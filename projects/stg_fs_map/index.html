<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Disk access, MMU, mmap, a simple overview. &#183;</title><meta name=title content="Disk access, MMU, mmap, a simple overview. &#183; "><meta name=description content="Explaining what happens when one mmap-s the content of a file."><link rel=canonical href=briztal.github.io/projects/stg_fs_map/><link type=text/css rel=stylesheet href=/briztal.github.io/css/main.bundle.min.29653ed199b7a749016920bb9715d240156e67049c90f12ffede5bb7f952606ecd8b0dd0c3f01d75af648960eddb25a879915d6e24858a75d11d9eed0607d9c6.css integrity="sha512-KWU+0Zm3p0kBaSC7lxXSQBVuZwSckPEv/t5bt/lSYG7Niw3Qw/Adda9kiWDt2yWoeZFdbiSFinXRHZ7tBgfZxg=="><script type=text/javascript src=/briztal.github.io/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
<script defer type=text/javascript id=script-bundle src=/briztal.github.io/js/main.bundle.min.5155d528b5217d2be660e88e103a0553710d2c94c85e3221100642905f3e6cbbb67b3760a44ab4f36703f12fbfe1d6f5b4545c3ae3a3f34784d919904ab7f1d7.js integrity="sha512-UVXVKLUhfSvmYOiOEDoFU3ENLJTIXjIhEAZCkF8+bLu2ezdgpEq082cD8S+/4db1tFRcOuOj80eE2RmQSrfx1w==" data-copy=Copy data-copied=Copied></script>
<script src=/briztal.github.io/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script>
<link rel=apple-touch-icon sizes=180x180 href=/briztal.github.io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/briztal.github.io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/briztal.github.io/favicon-16x16.png><link rel=manifest href=/briztal.github.io/site.webmanifest><meta property="og:title" content="Disk access, MMU, mmap, a simple overview."><meta property="og:description" content="Explaining what happens when one mmap-s the content of a file."><meta property="og:type" content="article"><meta property="og:url" content="briztal.github.io/projects/stg_fs_map/"><meta property="article:section" content="projects"><meta property="article:published_time" content="2025-06-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-16T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Disk access, MMU, mmap, a simple overview."><meta name=twitter:description content="Explaining what happens when one mmap-s the content of a file."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Personal Projects","name":"Disk access, MMU, mmap, a simple overview.","headline":"Disk access, MMU, mmap, a simple overview.","abstract":"Explaining what happens when one mmap-s the content of a file.","inLanguage":"en","url":"briztal.github.io\/projects\/stg_fs_map\/","author":{"@type":"Person","name":""},"copyrightYear":"2025","dateCreated":"2025-06-16T00:00:00\u002b00:00","datePublished":"2025-06-16T00:00:00\u002b00:00","dateModified":"2025-06-16T00:00:00\u002b00:00","mainEntityOfPage":"true","wordCount":"2964"}]</script><script src=/briztal.github.io/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/briztal.github.io class="text-base font-medium text-gray-500 hover:text-gray-900"></a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=briztal.github.io/projects/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Personal Projects">Projects</p></a><a href=briztal.github.io/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About me">About</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=briztal.github.io/projects/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Personal Projects">Projects</p></a></li><li class=mt-1><a href=briztal.github.io/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About me">About</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Disk access, MMU, mmap, a simple overview.</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-06-16T00:00:00+00:00>16 June 2025</time></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='return window.open("briztal.github.io/categories/operating-systems/","_self"),!1'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Operating Systems</span></span></span></div></div><div class="flex author"><div class=place-self-center><div class="text-2xl sm:text-lg"></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open id=TOCView class="toc-right mt-0 overflow-y-auto overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#context>Context</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#storage-device-management>Storage device management</a></li><li><a href=#mmu-virtual-address-space>MMU, virtual address space</a></li><li><a href=#mmap>MMAP</a></li><li><a href=#performance-considerations>Performance considerations</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#context>Context</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#storage-device-management>Storage device management</a></li><li><a href=#mmu-virtual-address-space>MMU, virtual address space</a></li><li><a href=#mmap>MMAP</a></li><li><a href=#performance-considerations>Performance considerations</a></li></ul></nav></div></details><script></script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h2 class="relative group">Context<div id=context class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#context aria-label=Anchor>#</a></span></h2><p>While writing an article about a component of my trading bot, I needed to explain what mapping a file&rsquo;s content in memory actually means, and cover the various performance issues that arise when doing so.</p><p>Since this explanation ended up taking more lines than what I originally had in mind and it seemed relevant to other topics, I decided to break this up into a dedicated article.</p><p>The original article can be found here :</p><h2 class="relative group">Introduction<div id=introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#introduction aria-label=Anchor>#</a></span></h2><p>In this article, I will provide an exploration into the banal act of
mapping a file&rsquo;s content to memory. Behind this simple act lies a trove of
hidden complexities that have a very concrete impact on code performance.</p><p>Once again, deepening our understanding of how this works also unlocks a new
set of design considerations leading to potential optimization techniques.<br>And giving such an overview of this topic is exactly the aim of this article.</p><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 0C114.6.0.0 114.6.0 256s114.6 256 256 256 256-114.6 256-256S397.4.0 256 0zm0 128c17.67.0 32 14.33 32 32 0 17.67-14.33 32-32 32s-32-14.3-32-32 14.3-32 32-32zm40 256h-80c-13.2.0-24-10.7-24-24s10.75-24 24-24h16v-64h-8c-13.25.0-24-10.75-24-24s10.8-24 24-24h32c13.25.0 24 10.75 24 24v88h16c13.25.0 24 10.75 24 24s-10.7 24-24 24z"/></svg></span></span><span class=dark:text-neutral-300><p>Acronyms used in this article :</p><ul><li><strong>PA</strong> will be used as an acronym for &ldquo;Physical Address&rdquo;, aka the addresses used in actual memory transactions on the bus (see below).</li><li><strong>VA</strong> will be used as an acronym for &ldquo;Virtual Address&rdquo;, aka the addresses used by code running in CPUs.</li></ul><p>The translation between the two and its impact will be covered in the next section.</p></span></div><h2 class="relative group">Storage device management<div id=storage-device-management class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#storage-device-management aria-label=Anchor>#</a></span></h2><p>First, let&rsquo;s cover how the kernel manages storage devices (disks).</p><p><strong>Some facts first.</strong></p><p>Processors are distributed systems with many components, among them :</p><ul><li>multiple <strong>CPUs</strong>, which all need to access DRAM.</li><li>multiple <strong>peripherals</strong> (Ethernet interface, USB interface, PCIE interface) that (in broad terms) are meant to be programmed by CPUs and that in some cases must access DRAM.</li><li>multiple <strong>DRAM</strong> slots.</li></ul><p>In order to make this different components interact with each others in an unified way, we introduce another component, the <strong>interconnect</strong>, abusively called &ldquo;memory bus&rdquo; in all this chapter.
It&rsquo;s role is to connect them all.
In particular :</p><ul><li>it defines the notion of physical address.</li><li>connected clients can be masters (can initiate transactions), slaves (can process transactions) or both.</li><li>it allows its masters to initiate implementation-defined transactions which target a given physical address. It is a functional simplification to consider that memory reads and writes are particular cases of such transactions.</li><li>it allows CPUs to configure and control peripherals by initiating transactions at PA ranges that peripherals are programmed to respond to.</li><li>it allows CPUs and peripherals to read or write to DRAM by initiating transactions at PA ranges that DRAM controllers are programmed to respond to.</li></ul><p>Storage devices like your average SATA or SSD drive :</p><ul><li>are meant to be pluggable and hence have their dedicated connectors and HW communication protocols.</li><li>are not meant to interface with processor interconnects directly. One cannot just make an access at a given PA and expect a storage device to just process this access.</li><li>cannot be accessed at a random granularity (byte, cache line, etc&mldr;). The same way the cache system cannot perform accesses at a granule inferior to the cache line, storage devices perform reads and writes at a minimal granularity, the sector size, which is a HW characteristic.</li><li>consequence : accessing the data contained in a storage device (ex : a SATA disk) is made via a dedicated peripheral connected to the interconnect, providing a HW interface to talk to your disk, and requiring a kernel driver to control with this peripheral.</li></ul><p><strong>A high level view.</strong></p><p>Here is a more complex but still extremely simplified view of how we can make code running in CPUs access (DRAM copy of) data located in a disk.</p><figure><img class="my-0 rounded-md" src=/briztal.github.io/images/bot/prv_fs_dsk.svg alt="prv fs dsk"><figcaption>Interacting with a hard drive.</figcaption></figure><p>Participants :</p><ul><li>IC (interconnect) : allowing all its clients to communicate with each other.</li><li>CPU : executes user code. Interconnect master only for this example&rsquo;s purpose.</li><li>DRAM : the actual memory of your system. Interconnect slave, processes transactions by converting them to actual DRAM read and writes.</li><li>Disk : a storage device that is controlled via an implementation-defined protocol only handled by the storage interface. Not directly connected to the interconnect.</li><li>Storage interface : interfaces the interconnect and the disks. Must be programmed by an external entity to do so. Interconnect slave : processes memory transactions targeting its address range as configuration requests, which allows external entities to control its behavior, for example to power up the disk, initiate a sector read or write (etc&mldr;). Interconnect master : forwards disk data to DRAM via write interconnect transactions.</li></ul><p>Now, let&rsquo;s describe the different sequences involved to allow CPUs to read data at two different locations on the disk. We will here suppose that CPUs can read at arbitrary PAs, and the next section will complexify this model.</p><p><strong>Step A : storage interface setup.</strong></p><p>The kernel running on CPU 0 does the following things :</p><ul><li>it allocates two buffers of DRAM using its primary memory allocator, in a zone that allows the storage interface to perform memory transactions (DMA16 or more likely DMA32).</li><li>it sends control transactions to the storage interface via the memory bus, to instruct it to perform two disk reads and to store the resulting data at the PAs of the buffers that it allocated.</li></ul><p><strong>Step B : disk reads.</strong></p><p>The storage interface understands the instructions sent by the CPU and starts the disk read sequences. The disk will respond with two consecutive data streams, that the storage interface will then transmit to DRAM using memory bus transactions (DMA).</p><p>Once the reads are done, the storage interface notifies the kernel of their completion by sending an IRQ targeting one of the CPUs.</p><p><strong>Step C : CPU access.</strong></p><p>Now that DRAM buffers have been initialized with a copy of the data at the required disk locations, CPU can read those buffers by simply performing memory reads at PAs within buffers A and B (provided that they have invalidated their caches for the memory ranges of A and B).</p><p>Now, an immediate consequence of what we covered here is that CPUs <em>cannot</em> modify the data on disk themselves. All they can do is to modify the DRAM copy.</p><p>If updates need to be propagated to disk, the kernel will need to initiate another transaction (a disk write this time), instructing the storage interface to read from DRAM and write data to disk.</p><p>From userspace, this is typically initiated via fsync or msync.</p><h2 class="relative group">MMU, virtual address space<div id=mmu-virtual-address-space class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#mmu-virtual-address-space aria-label=Anchor>#</a></span></h2><p>In the previous section, we assumed that the different CPUs in the system could write to arbitrary PAs.</p><p>The reality is more nuanced, as PA access is critical :</p><ul><li>first, allowing any userspace process to access any PA basically allows it to read any other process&rsquo;s data. Just for security reasons, we can&rsquo;t let that happen.</li><li>then, we saw in the previous sections that some PAs correspond to HW configuration ranges, and if mis-used, can cause HW faults which often just make the system immediately panic. For practicality, we also cannot let that happen.</li><li>finally, most programs are not meant to deal with PA itself. Physical memory management is a critical task of the kernel, and physical pages are usually allocated in a non-contiguous manner, on a page-per-page basis. Programs often need to access large contiguous memory regions (like their whole 4MiB wide executable), and hence, have needs that are incompatible with how physical memory is intrinsically managed by the kernel.</li></ul><p>For all those reasons and others, code running on CPUs (whether it be kernel code or userspace code) does not operate with physical addresses directly.</p><p>Rather, it operates using virtual addresses, which translate (or not) into physical addresses using an in-memory structure that SW can configure but whose format is dictated by the HW, called a page table. Every CPU in the system is equipped with a Memory Management Unit or MMU, which translates any VA used by the CPU to the corresponding PA.</p><p>This article will not dive into the format of the pagetable, but here are a few facts worth mentioning :</p><ul><li>VA->PA translation is done at the aligned page granule. Virtual memory is divided into pages of usually 4, 16 or 64 KiBs and each virtual page can map to at most one physical page. When I say map to, understand &lsquo;set by the pagetable content to be translated to&rsquo;</li><li>multiple virtual pages can map to the same physical page.</li><li>the pagetable contains the translation data and also attributes like translation permissions (can data be read, written, executed, and by who ?) and cacheability.</li><li>the pagetable is dynamically writeable, but usually by privileged software (kernel) only.</li></ul><p>Now let&rsquo;s add some details on how the CPUs will need to map memory to perform the various transactions described in the previous section :</p><ul><li>to program the storage interface, CPUs will need to map the PA region corresponding to the peripheral&rsquo;s control range into a range in their virtual address space (in reality, into the kernel&rsquo;s virtual address space which all CPUs use in kernel mode), and perform memory accessed from this virtual range. The mapping will be RWnE (read/write/non-execute) and non-cacheable, as we want the control transaction not to be affected by the CPU&rsquo;s cache system.</li><li>to read from and write to DRAM, CPUs will again need to map the PA regions corresponding to the buffer A and B into the kernel&rsquo;s virtual address space and perform their accesses from this virtual range. The mappings will be cacheable, but a few precautions will need to be taken to ensure that reads see the data written by the storage interface, and that reads by the storage interface (during disk writes) see the writes made by the CPU :<ul><li>before reading data written by the storage interface, CPUs will need to invalidate the ranges for buffers A and B, so that when they read at those addresses, data is re-fetched from memory.</li><li>before instructing the storage interface to write to disk, CPUs will need to flush the ranges for buffers A and B, so that the writes made by CPUs are propagated to memory and observed by the storage interface.</li></ul></li></ul><p>To illustrate, here would be how the translation summary would look like for <em>just</em> our example. Here we assume that we have 4KiB (0x1000b) pages, a 3 bytes virtual address space (0x1000000 bytes of addressable VA), a 2 bytes physical address space (0x10000 bytes of addressable PA), among which :</p><ul><li>the 7 first pages are mapped, and the remaining part of the PA space is not mapped.</li><li>the storage interface responds to transactions targeting the first page of PA.</li><li>the DRAM controller responds to transactions targeting the 4 next pages of PA.</li><li>another peripheral, the UART, responds to transactions targeting the next (and last) page of PA.</li></ul><figure><img class="my-0 rounded-md" src=/briztal.github.io/images/bot/prv_va_pa_trs.svg alt="prv sync"><figcaption>Translations in our example.</figcaption></figure><p>As one can expect :</p><ul><li>one VA page maps the control range of the storage interface, and is used by CPUs to configure it to initiate disk transactions.</li><li>two VA pages map buffers A and B (let&rsquo;s assume that they are page-sized) who are located in DRAM, so that cpus can read and write the DRAM copy of the disk data. Note that both buffers have non-contiguous PA and VA locations.</li><li>No one maps the UART.</li></ul><blockquote><p>The attentive reader may ask : how are CPUs executing any code ?
Indeed, code resides in memory somewhere in PA and hence, needs a dedicated VA mapping for CPUs to read it.
In an effort to keep this diagram simple, I did not add this info, but in reality, there should be DRAM pages allocated to contain code, and a contiguous VA region that maps those PA pages.</p></blockquote><p>An important notion to remember is that if two CPUs run two user programs that want to access the same region of disk data, the CPUs may map exactly the same physical pages (buffers) allocated by the kernel under the hood. Or they may map different copies transparently made by the kernel. The next section will cover the modalities of this system.</p><h2 class="relative group">MMAP<div id=mmap class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#mmap aria-label=Anchor>#</a></span></h2><p>So far, we know that :</p><ul><li>the kernel handles storage operations (disk reads and writes) transparently on behalf of users, by allocating buffers and initiating disk read and write to / from those buffers via one of its drivers that interacts with the storage interface.</li><li>Upon completion of disk read requests, userland code can access those buffers by instructing the kernel to map those buffers in the user&rsquo;s virtual address space.</li></ul><p>This section will elaborate on the second part.</p><p>There are two ways for user code to access disk data :</p><ul><li>file operations like read, write, readat, writeat, et al. Those operations involve invoking the kernel and do not scale well in practice.</li><li>mapping the buffers managed by the kernel to contain disk data in userland and let user code read and write freely.</li></ul><p>We will focus on the second method, and in particular, in the way users can configure the mapping made by the kernel.</p><p>The main system call to map a file into userspace is mmap. It involves the following steps :</p><ul><li>user code makes an open call to open the proper disk file and acquire its (shared) ownership.</li><li>user code calls mmap with chosen parameters so that the buffers managed by the kernel are mapped into its virtual address space.</li></ul><p>Note that the kernel does not necessarily need to read the entire disk file and populate all the DRAM buffers to contain all the file&rsquo;s data.
Rather, it can choose to defer the disk reads to when the user code needs it : it will allocate a VA region of the size of the file in the user&rsquo;s virtual address space, and let the VA pages unmapped. When the user code will access those VAs, the HW will generate a translation fault, which will be handled by the kernel. The kernel will then put the user code to sleep, perform the disk read, and upon completion, resume the user process execution at the instruction that originally faulted.</p><p>Mmap takes the following parameters :</p><ul><li>permissions : condition the way user code can access the mapped data :<ul><li>readability : if readable, the user can perform memory reads on the mapped VA region; if not, it cannot.</li><li>writeability : if writeable, the user can perform memory writes on the mapped VA region; if not, it cannot.</li><li>executability : if executable, the user can branch to the mapped VA region and execute its content; if not, it cannot.</li></ul></li><li>shareability : condition if the running process sees disk writes from other programs and vice versa.<ul><li>private : the process sees its local copy of the file. It behaves exactly as if the kernel had read the whole file at map time and the user process was mapping this copy. In practice this is more nuanced than this, as copying (potentially GiB-wide) files results in a huge memory consumption. The kernel likely implements Copy-on-Write (CoW) mechanisms to reduce the memory cost. Writes to this private copy will not be (natively) propagateable to disk.</li><li>shareable: the process uses the kernel shared buffers and no private copy is used. Updates to those buffers will :<ul><li>be visible to any other process mapping the same buffers (i.e mapping the same portion of the same file) at some point.</li><li>be propagated to disk when msync is called.</li></ul></li></ul></li></ul><blockquote><p>It is typically considered a security vulnerability to leave a VA range WE (write + execute) as it allows an attacker with write capabilities to escalate into arbitrary execution capabilities.</p></blockquote><blockquote><p>This article will not elaborate too much on how CoW works, but here is a simple (and probably suboptimal) way it can be achieved : when a process maps a file in private and this file is mapped by other processes, the kernel first disallows any writes to this file&rsquo;s shared buffers, then maps those in the process&rsquo;s virtual address space.
Any write to those buffers (by anyone) will generate a translation fault which the kernel will handle by effectively duplicating the buffers, and map the copy in the virtual address space of the process that required private access.
Other processes keep the shared buffers mapped.
Once that&rsquo;s done, buffer writes are allowed again for both shared and private buffers.</p></blockquote><h2 class="relative group">Performance considerations<div id=performance-considerations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#performance-considerations aria-label=Anchor>#</a></span></h2><p>The two biggest performance factors to consider when mapping a file are :</p><ul><li>do we need to write to the file ? If not, then we can map as readable and simplify the kernel&rsquo;s life, as it is guaranteed that we never modify the mapped buffers, which reduces its CoW implementation.</li><li>do we need to work on our local copy of the file, or is it acceptable to :<ul><li>observe updates made to the file by other entities.</li><li>have our own updates observed by other entities that map this file as shareable.</li></ul></li></ul><p>If we choose to access the file in shareable, we have to deal with the following performance issues :</p><ul><li>If someone else maps the same portion of the same file in private, we could see a perf hit when writes are performed for the first time on a page, due to the kernel&rsquo;s CoW implementation.</li><li>If us and a remote entity access (read or write) the same locations, then the CPU&rsquo;s cache system needs to synchronize those accesses, leading to real-time perf hits. Any multiprocessing system where entities map the same underlying physical pages must be designed in a way that minimizes the simultaneous access to those pages, or be prepared to pay a big performance cost otherwise.</li></ul><p>If we choose to access the file in private, we have to deal with the following performance issue :</p><ul><li>If someone else maps the file either in private or in shareable, then the same buffers may be mapped (via the kernel&rsquo;s CoW system) and we may experience random perf hits when us or another processes mapping the file writes to a CoW buffer.</li></ul></div></div><script>var oid="views_projects/stg_fs_map.md",oid_likes="likes_projects/stg_fs_map.md"</script><script type=text/javascript src=/briztal.github.io/js/page.min.b06a29d42a4ed16787978e2eee1e8c797b7698db2bc14ccee78f5c80ac566fc996190a73ad80a5e987558474b20b96fa38f7d85b405f165ff72b7b163c5ad11b.js integrity="sha512-sGop1CpO0WeHl44u7h6MeXt2mNsrwUzO549cgKxWb8mWGQpzrYCl6YdVhHSyC5b6OPfYW0BfFl/3K3sWPFrRGw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=briztal.github.io/projects/bot/bot_1_top/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Trading core : high level view</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-06-13T00:00:00+00:00>13 June 2025</time></span></span></a></span>
<span><a class="flex text-right group ml-3" href=briztal.github.io/projects/bot/bot_2_prv/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Trading bot : data provider.</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-06-19T00:00:00+00:00>19 June 2025</time></span></span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/briztal.github.io/js/process.min.62060bb247f4de2b6dde45903668fefb68d792f365587605177b1227c0cf43588701edaca0cb40e2c8e2789bd5ce67c1d2a215b9fb258c3496a7cd25e7cb5fdf.js integrity="sha512-YgYLskf03itt3kWQNmj++2jXkvNlWHYFF3sSJ8DPQ1iHAe2soMtA4sjieJvVzmfB0qIVufsljDSWp80l58tf3w=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=briztal.github.io style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>